{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Satip Documentation Site \u00b6 We can add a to do list: With tasks like this And optional tick boxes Footnotes can also be added 1 We can also display MathJax like this: \\(2+2=5\\) No matter where this is added in the text it will be rendered in the footer \u21a9","title":"Home"},{"location":"#welcome-to-the-satip-documentation-site","text":"We can add a to do list: With tasks like this And optional tick boxes Footnotes can also be added 1 We can also display MathJax like this: \\(2+2=5\\) No matter where this is added in the text it will be rendered in the footer \u21a9","title":"Welcome to the Satip Documentation Site"},{"location":"EUMETSAT%20Download%20Example/","text":"EUMETSAT Download Example \u00b6 This notebook outlines how the satip module can be used to download data from EUMETSAT Imports \u00b6 We will begin by importing the relevant libraries, you can install the latest version of satip using pip install satip from satip import eumetsat as ems import os import dotenv User Input \u00b6 data_dir = '../data/raw' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db' Authorising API Access \u00b6 First we'll load the the environment variables and assign the user key and secret dotenv . load_dotenv ( env_vars_fp ) user_key = os . environ . get ( 'user_key' ) user_secret = os . environ . get ( 'user_secret' ) Downloading the Data \u00b6 We have to initialise the DownloadManager, then we can pass date ranges over which all data will be downloaded start_date = '2020-10-01 00:00' end_date = '2020-10-01 00:30' dm = ems . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp ) dm . download_datasets ( start_date , end_date ) 100% 6/6 [00:00 < 00:00, 0.00s/it] Metadata for each of the files is saved to a database df_metadata = dm . get_df_metadata () df_metadata . head () id start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded 0 1 2020-10-01 00:00:07.767000 2020-10-01 00:04:14.060000 2020-10-01 00:04:14.060000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001000414.060000000Z-NA 99819 0 2020-10-13 00:24:02.786606 1 2 2020-10-01 00:05:07.523000 2020-10-01 00:09:13.818000 2020-10-01 00:09:13.818000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001000913.818000000Z-NA 99819 0 2020-10-13 00:24:09.229091 2 3 2020-10-01 00:10:07.281000 2020-10-01 00:14:13.576000 2020-10-01 00:14:13.576000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001001413.576000000Z-NA 99819 0 2020-10-13 00:24:15.793064 3 4 2020-10-01 00:15:07.040000 2020-10-01 00:19:13.336000 2020-10-01 00:19:13.336000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001001913.336000000Z-NA 99819 0 2020-10-13 00:24:22.183809 4 5 2020-10-01 00:20:08.602000 2020-10-01 00:24:14.899000 2020-10-01 00:24:14.899000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001002414.899000000Z-NA 99819 0 2020-10-13 00:24:28.338515","title":"Downloading from EUMETSAT"},{"location":"EUMETSAT%20Download%20Example/#eumetsat-download-example","text":"This notebook outlines how the satip module can be used to download data from EUMETSAT","title":"EUMETSAT Download Example"},{"location":"EUMETSAT%20Download%20Example/#imports","text":"We will begin by importing the relevant libraries, you can install the latest version of satip using pip install satip from satip import eumetsat as ems import os import dotenv","title":"Imports"},{"location":"EUMETSAT%20Download%20Example/#user-input","text":"data_dir = '../data/raw' env_vars_fp = '../.env' metadata_db_fp = '../data/EUMETSAT_metadata.db'","title":"User Input"},{"location":"EUMETSAT%20Download%20Example/#authorising-api-access","text":"First we'll load the the environment variables and assign the user key and secret dotenv . load_dotenv ( env_vars_fp ) user_key = os . environ . get ( 'user_key' ) user_secret = os . environ . get ( 'user_secret' )","title":"Authorising API Access"},{"location":"EUMETSAT%20Download%20Example/#downloading-the-data","text":"We have to initialise the DownloadManager, then we can pass date ranges over which all data will be downloaded start_date = '2020-10-01 00:00' end_date = '2020-10-01 00:30' dm = ems . DownloadManager ( user_key , user_secret , data_dir , metadata_db_fp ) dm . download_datasets ( start_date , end_date ) 100% 6/6 [00:00 < 00:00, 0.00s/it] Metadata for each of the files is saved to a database df_metadata = dm . get_df_metadata () df_metadata . head () id start_date end_date result_time platform_short_name platform_orbit_type instrument_name sensor_op_mode center_srs_name center_position file_name file_size missing_pct downloaded 0 1 2020-10-01 00:00:07.767000 2020-10-01 00:04:14.060000 2020-10-01 00:04:14.060000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001000414.060000000Z-NA 99819 0 2020-10-13 00:24:02.786606 1 2 2020-10-01 00:05:07.523000 2020-10-01 00:09:13.818000 2020-10-01 00:09:13.818000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001000913.818000000Z-NA 99819 0 2020-10-13 00:24:09.229091 2 3 2020-10-01 00:10:07.281000 2020-10-01 00:14:13.576000 2020-10-01 00:14:13.576000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001001413.576000000Z-NA 99819 0 2020-10-13 00:24:15.793064 3 4 2020-10-01 00:15:07.040000 2020-10-01 00:19:13.336000 2020-10-01 00:19:13.336000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001001913.336000000Z-NA 99819 0 2020-10-13 00:24:22.183809 4 5 2020-10-01 00:20:08.602000 2020-10-01 00:24:14.899000 2020-10-01 00:24:14.899000 MSG3 GEO SEVIRI RSS EPSG:4326 0 9.5 MSG3-SEVI-MSG15-0100-NA-20201001002414.899000000Z-NA 99819 0 2020-10-13 00:24:28.338515","title":"Downloading the Data"},{"location":"OCF/","text":"Open Climate Fix \u00b6 Open Climate Fix is a new non-profit research and development lab, totally focused on reducing greenhouse gas emissions as rapidly as possible. Every part of the organisation is designed to maximise climate impact, such as our open and collaborative approach, our rapid prototyping, and our attention on finding scalable & practical solutions. By using an open-source approach, we can draw upon a much larger pool of expertise than any individual company, so combining existing islands of knowledge and accelerating progress. Our approach will be to search for ML (Machine Learning) problems where, if we solve a well-defined ML task, then there is likely to be a large climate impact. Then, for each of these challenges, we will: Collate & release data , and write software tools to make it super-easy for people to consume this data. Run a collaborative \u201cglobal research project\u201d where everyone from 16-year-olds to PhD students to corporate research labs can help solve the ML task (and, over the last 6 weeks, we have received over 300 emails from people who\u2019d love to get involved). Help to put good solutions into production , once the community has developed them, so we can be reducing emissions ASAP. Sign up to our newsletter","title":"Open Climate Fix"},{"location":"OCF/#open-climate-fix","text":"Open Climate Fix is a new non-profit research and development lab, totally focused on reducing greenhouse gas emissions as rapidly as possible. Every part of the organisation is designed to maximise climate impact, such as our open and collaborative approach, our rapid prototyping, and our attention on finding scalable & practical solutions. By using an open-source approach, we can draw upon a much larger pool of expertise than any individual company, so combining existing islands of knowledge and accelerating progress. Our approach will be to search for ML (Machine Learning) problems where, if we solve a well-defined ML task, then there is likely to be a large climate impact. Then, for each of these challenges, we will: Collate & release data , and write software tools to make it super-easy for people to consume this data. Run a collaborative \u201cglobal research project\u201d where everyone from 16-year-olds to PhD students to corporate research labs can help solve the ML task (and, over the last 6 weeks, we have received over 300 emails from people who\u2019d love to get involved). Help to put good solutions into production , once the community has developed them, so we can be reducing emissions ASAP. Sign up to our newsletter","title":"Open Climate Fix"},{"location":"API/eumetsat/","text":"EUMETSAT \u00b6","title":"EUMETSAT"},{"location":"API/eumetsat/#eumetsat","text":"","title":"EUMETSAT"},{"location":"API/utils/","text":"Utilities \u00b6 The Satip utils module is a collection of small functions and classes that are intended to reduce the amount of boilerplate code needed, as well as make common patterns shorter and easier. Create Markdown Table \u00b6 Returns a string for a markdown table, formatted according to the dictionary passed as table_info Parameters: Name Type Description Default table_info dict Mapping from index to values required index_name str Name to use for the index column 'Id' Returns: Type Description str md_str: Markdown formatted table string Examples: >>> table_info = { 'Apples' : { 'Cost' : '40p' , 'Colour' : 'Red/green' , }, 'Oranges' : { 'Cost' : '50p' , 'Colour' : 'Orange' , }, } >>> md_str = create_markdown_table ( table_info , index_name = 'Fruit' ) >>> print ( md_str ) | Fruit | Cost | Colour | | : --------| : -------| : ----------| | Apples | 40 p | Red / green | | Oranges | 50 p | Orange | Source code in satip/utils.py def create_markdown_table ( table_info : dict , index_name : str = 'Id' ) -> str : \"\"\" Returns a string for a markdown table, formatted according to the dictionary passed as `table_info` Parameters: table_info: Mapping from index to values index_name: Name to use for the index column Returns: md_str: Markdown formatted table string Example: >>> table_info = { 'Apples': { 'Cost': '40p', 'Colour': 'Red/green', }, 'Oranges': { 'Cost': '50p', 'Colour': 'Orange', }, } >>> md_str = create_markdown_table(table_info, index_name='Fruit') >>> print(md_str) | Fruit | Cost | Colour | |:--------|:-------|:----------| | Apples | 40p | Red/green | | Oranges | 50p | Orange | \"\"\" df_info = pd . DataFrame ( table_info ) . T df_info . index . name = index_name md_str = df_info . to_markdown () return md_str Set Up Logging \u00b6 set_up_logging initialises and configures a custom logger for satip . The logging level of the file and Jupyter outputs are specified by main_logging_level whilst the Slack handler uses slack_logging_level . There are three core ways that logs are broadcasted: Logging to a specified file Logging to Jupyter cell outputs Logging to Slack Note that the value passed for main_logging_level and slack_logging_level must be one of: 'CRITICAL' 'FATAL' 'ERROR' 'WARNING' 'WARN' 'INFO' 'DEBUG' 'NOTSET' Parameters: Name Type Description Default name str Name of the logger required log_fp str Filepath where the logs will be stored required main_logging_level str Logging level for file and Jupyter 'DEBUG' slack_logging_level str Logging level for Slack 'CRITICAL' slack_webhook_url str Webhook for the log Slack channel None slack_id str Option user-id to mention in Slack None Returns: Type Description Logger logger: Custom satip logger Examples: Here we'll create a custom logger that saves data to the file 'test_log.txt' and also sends Slack messages to the specified user and channel. >>> from satip.utils import set_up_logging >>> import logging >>> logger = set_up_logging ( 'test_log' , 'test_log.txt' , slack_id = slack_id , slack_webhook_url = slack_webhook_url ) >>> logger . log ( logging . INFO , 'This will output to file and Jupyter but not to Slack as it is not critical' ) '2020-10-20 10:24:35,367 - INFO - This will output to file and Jupyter but not to Slack as it is not critical' Source code in satip/utils.py def set_up_logging ( name : str , log_fp : str , main_logging_level : str = 'DEBUG' , slack_logging_level : str = 'CRITICAL' , slack_webhook_url : str = None , slack_id : str = None ) -> logging . Logger : \"\"\" `set_up_logging` initialises and configures a custom logger for `satip`. The logging level of the file and Jupyter outputs are specified by `main_logging_level` whilst the Slack handler uses `slack_logging_level`. There are three core ways that logs are broadcasted: - Logging to a specified file - Logging to Jupyter cell outputs - Logging to Slack Note that the value passed for `main_logging_level` and `slack_logging_level` must be one of: - 'CRITICAL' - 'FATAL' - 'ERROR' - 'WARNING' - 'WARN' - 'INFO' - 'DEBUG' - 'NOTSET' Parameters: name: Name of the logger log_fp: Filepath where the logs will be stored main_logging_level: Logging level for file and Jupyter slack_logging_level: Logging level for Slack slack_webhook_url: Webhook for the log Slack channel slack_id: Option user-id to mention in Slack Returns: logger: Custom satip logger Example: Here we'll create a custom logger that saves data to the file 'test_log.txt' and also sends Slack messages to the specified user and channel. >>> from satip.utils import set_up_logging >>> import logging >>> logger = set_up_logging('test_log', 'test_log.txt', slack_id=slack_id, slack_webhook_url=slack_webhook_url) >>> logger.log(logging.INFO, 'This will output to file and Jupyter but not to Slack as it is not critical') '2020-10-20 10:24:35,367 - INFO - This will output to file and Jupyter but not to Slack as it is not critical' \"\"\" # Initialising logger logger = logging . getLogger ( name ) # Configuring log level logging_levels = [ 'CRITICAL' , 'FATAL' , 'ERROR' , 'WARNING' , 'WARN' , 'INFO' , 'DEBUG' , 'NOTSET' ] assert main_logging_level in logging_levels , f \"main_logging_level must be one of { ', ' . join ( logging_levels ) } \" assert slack_logging_level in logging_levels , f \"slack_logging_level must be one of { ', ' . join ( logging_levels ) } \" logger . setLevel ( getattr ( logging , main_logging_level )) # Defining global formatter formatter = logging . Formatter ( ' %(asctime)s - %(levelname)s - %(message)s ' ) # Configuring Jupyter output handler stream_handler = logging . StreamHandler () stream_handler . setFormatter ( formatter ) logger . addHandler ( stream_handler ) # Configuring file output handler file_handler = logging . FileHandler ( log_fp , mode = 'a' ) file_handler . setFormatter ( formatter ) file_handler . setLevel ( getattr ( logging , main_logging_level )) logger . addHandler ( file_handler ) # Configuring slack output handler if slack_webhook_url is not None : slack_handler = SlackHandler ( username = 'logger' , url = slack_webhook_url , mention = slack_id ) slack_handler . setFormatter ( SlackFormatter ()) slack_handler . setLevel ( getattr ( logging , slack_logging_level )) logger . addHandler ( slack_handler ) return logger","title":"Utilities"},{"location":"API/utils/#utilities","text":"The Satip utils module is a collection of small functions and classes that are intended to reduce the amount of boilerplate code needed, as well as make common patterns shorter and easier. Create Markdown Table","title":"Utilities"},{"location":"API/utils/#satip.utils.create_markdown_table","text":"Returns a string for a markdown table, formatted according to the dictionary passed as table_info Parameters: Name Type Description Default table_info dict Mapping from index to values required index_name str Name to use for the index column 'Id' Returns: Type Description str md_str: Markdown formatted table string Examples: >>> table_info = { 'Apples' : { 'Cost' : '40p' , 'Colour' : 'Red/green' , }, 'Oranges' : { 'Cost' : '50p' , 'Colour' : 'Orange' , }, } >>> md_str = create_markdown_table ( table_info , index_name = 'Fruit' ) >>> print ( md_str ) | Fruit | Cost | Colour | | : --------| : -------| : ----------| | Apples | 40 p | Red / green | | Oranges | 50 p | Orange | Source code in satip/utils.py def create_markdown_table ( table_info : dict , index_name : str = 'Id' ) -> str : \"\"\" Returns a string for a markdown table, formatted according to the dictionary passed as `table_info` Parameters: table_info: Mapping from index to values index_name: Name to use for the index column Returns: md_str: Markdown formatted table string Example: >>> table_info = { 'Apples': { 'Cost': '40p', 'Colour': 'Red/green', }, 'Oranges': { 'Cost': '50p', 'Colour': 'Orange', }, } >>> md_str = create_markdown_table(table_info, index_name='Fruit') >>> print(md_str) | Fruit | Cost | Colour | |:--------|:-------|:----------| | Apples | 40p | Red/green | | Oranges | 50p | Orange | \"\"\" df_info = pd . DataFrame ( table_info ) . T df_info . index . name = index_name md_str = df_info . to_markdown () return md_str Set Up Logging","title":"satip.utils.create_markdown_table"},{"location":"API/utils/#satip.utils.set_up_logging","text":"set_up_logging initialises and configures a custom logger for satip . The logging level of the file and Jupyter outputs are specified by main_logging_level whilst the Slack handler uses slack_logging_level . There are three core ways that logs are broadcasted: Logging to a specified file Logging to Jupyter cell outputs Logging to Slack Note that the value passed for main_logging_level and slack_logging_level must be one of: 'CRITICAL' 'FATAL' 'ERROR' 'WARNING' 'WARN' 'INFO' 'DEBUG' 'NOTSET' Parameters: Name Type Description Default name str Name of the logger required log_fp str Filepath where the logs will be stored required main_logging_level str Logging level for file and Jupyter 'DEBUG' slack_logging_level str Logging level for Slack 'CRITICAL' slack_webhook_url str Webhook for the log Slack channel None slack_id str Option user-id to mention in Slack None Returns: Type Description Logger logger: Custom satip logger Examples: Here we'll create a custom logger that saves data to the file 'test_log.txt' and also sends Slack messages to the specified user and channel. >>> from satip.utils import set_up_logging >>> import logging >>> logger = set_up_logging ( 'test_log' , 'test_log.txt' , slack_id = slack_id , slack_webhook_url = slack_webhook_url ) >>> logger . log ( logging . INFO , 'This will output to file and Jupyter but not to Slack as it is not critical' ) '2020-10-20 10:24:35,367 - INFO - This will output to file and Jupyter but not to Slack as it is not critical' Source code in satip/utils.py def set_up_logging ( name : str , log_fp : str , main_logging_level : str = 'DEBUG' , slack_logging_level : str = 'CRITICAL' , slack_webhook_url : str = None , slack_id : str = None ) -> logging . Logger : \"\"\" `set_up_logging` initialises and configures a custom logger for `satip`. The logging level of the file and Jupyter outputs are specified by `main_logging_level` whilst the Slack handler uses `slack_logging_level`. There are three core ways that logs are broadcasted: - Logging to a specified file - Logging to Jupyter cell outputs - Logging to Slack Note that the value passed for `main_logging_level` and `slack_logging_level` must be one of: - 'CRITICAL' - 'FATAL' - 'ERROR' - 'WARNING' - 'WARN' - 'INFO' - 'DEBUG' - 'NOTSET' Parameters: name: Name of the logger log_fp: Filepath where the logs will be stored main_logging_level: Logging level for file and Jupyter slack_logging_level: Logging level for Slack slack_webhook_url: Webhook for the log Slack channel slack_id: Option user-id to mention in Slack Returns: logger: Custom satip logger Example: Here we'll create a custom logger that saves data to the file 'test_log.txt' and also sends Slack messages to the specified user and channel. >>> from satip.utils import set_up_logging >>> import logging >>> logger = set_up_logging('test_log', 'test_log.txt', slack_id=slack_id, slack_webhook_url=slack_webhook_url) >>> logger.log(logging.INFO, 'This will output to file and Jupyter but not to Slack as it is not critical') '2020-10-20 10:24:35,367 - INFO - This will output to file and Jupyter but not to Slack as it is not critical' \"\"\" # Initialising logger logger = logging . getLogger ( name ) # Configuring log level logging_levels = [ 'CRITICAL' , 'FATAL' , 'ERROR' , 'WARNING' , 'WARN' , 'INFO' , 'DEBUG' , 'NOTSET' ] assert main_logging_level in logging_levels , f \"main_logging_level must be one of { ', ' . join ( logging_levels ) } \" assert slack_logging_level in logging_levels , f \"slack_logging_level must be one of { ', ' . join ( logging_levels ) } \" logger . setLevel ( getattr ( logging , main_logging_level )) # Defining global formatter formatter = logging . Formatter ( ' %(asctime)s - %(levelname)s - %(message)s ' ) # Configuring Jupyter output handler stream_handler = logging . StreamHandler () stream_handler . setFormatter ( formatter ) logger . addHandler ( stream_handler ) # Configuring file output handler file_handler = logging . FileHandler ( log_fp , mode = 'a' ) file_handler . setFormatter ( formatter ) file_handler . setLevel ( getattr ( logging , main_logging_level )) logger . addHandler ( file_handler ) # Configuring slack output handler if slack_webhook_url is not None : slack_handler = SlackHandler ( username = 'logger' , url = slack_webhook_url , mention = slack_id ) slack_handler . setFormatter ( SlackFormatter ()) slack_handler . setLevel ( getattr ( logging , slack_logging_level )) logger . addHandler ( slack_handler ) return logger","title":"satip.utils.set_up_logging"}]}